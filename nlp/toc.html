<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- sidebar iframe generated using mdBook

        This is a frame, and not included directly in the page, to control the total size of the
        book. The TOC contains an entry for each page, so if each page includes a copy of the TOC,
        the total size of the page becomes O(n**2).

        The frame is only used as a fallback when JS is turned off. When it's on, the sidebar is
        instead added to the main page by `toc.js` instead. The JavaScript mode is better
        because, when running in a `file:///` URL, the iframed page would not be Same-Origin as
        the rest of the page, so the sidebar and the main page theme would fall out of sync.
        -->
        <meta charset="UTF-8">
        <meta name="robots" content="noindex">
        <!-- Custom HTML head -->
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">
        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">
        <!-- Custom theme stylesheets -->
    </head>
    <body class="sidebar-iframe-inner">
        <ol class="chapter"><li class="chapter-item expanded affix "><a href="index.html" target="_parent">Introduction</a></li><li class="chapter-item expanded affix "><li class="part-title">Natural Language Processing</li><li class="chapter-item expanded "><a href="llms/index.html" target="_parent"><strong aria-hidden="true">1.</strong> LLMs</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="llms/architecture/index.html" target="_parent"><strong aria-hidden="true">1.1.</strong> Architecture</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="llms/architecture/attention.html" target="_parent"><strong aria-hidden="true">1.1.1.</strong> Attention</a></li><li class="chapter-item expanded "><a href="llms/architecture/transformer.html" target="_parent"><strong aria-hidden="true">1.1.2.</strong> Transformer</a></li><li class="chapter-item expanded "><a href="llms/architecture/moe.html" target="_parent"><strong aria-hidden="true">1.1.3.</strong> Mixture of Experts</a></li><li class="chapter-item expanded "><a href="llms/architecture/encoders.html" target="_parent"><strong aria-hidden="true">1.1.4.</strong> Encoders</a></li><li class="chapter-item expanded "><a href="llms/architecture/decoders.html" target="_parent"><strong aria-hidden="true">1.1.5.</strong> Decoders</a></li><li class="chapter-item expanded "><a href="llms/architecture/encoder_decoder.html" target="_parent"><strong aria-hidden="true">1.1.6.</strong> Encoder-Decoder</a></li><li class="chapter-item expanded "><a href="llms/architecture/mla.html" target="_parent"><strong aria-hidden="true">1.1.7.</strong> Multi-Latent Attention</a></li></ol></li><li class="chapter-item expanded "><a href="llms/prompting/index.html" target="_parent"><strong aria-hidden="true">1.2.</strong> Prompting</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="llms/prompting/prompt_engineering.html" target="_parent"><strong aria-hidden="true">1.2.1.</strong> Prompt Engineering</a></li><li class="chapter-item expanded "><a href="llms/prompting/icl.html" target="_parent"><strong aria-hidden="true">1.2.2.</strong> In-Context Learning</a></li><li class="chapter-item expanded "><a href="llms/prompting/few_shot.html" target="_parent"><strong aria-hidden="true">1.2.3.</strong> Few-Shot Learning</a></li><li class="chapter-item expanded "><a href="llms/prompting/cot.html" target="_parent"><strong aria-hidden="true">1.2.4.</strong> Chain of Thought</a></li><li class="chapter-item expanded "><a href="llms/prompting/tot.html" target="_parent"><strong aria-hidden="true">1.2.5.</strong> Tree of Thought</a></li><li class="chapter-item expanded "><a href="llms/prompting/soft.html" target="_parent"><strong aria-hidden="true">1.2.6.</strong> Soft prompts</a></li><li class="chapter-item expanded "><a href="llms/prompting/hard.html" target="_parent"><strong aria-hidden="true">1.2.7.</strong> Hard prompts</a></li></ol></li><li class="chapter-item expanded "><a href="llms/fine_tuning/index.html" target="_parent"><strong aria-hidden="true">1.3.</strong> Fine-tuning</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="llms/fine_tuning/sft.html" target="_parent"><strong aria-hidden="true">1.3.1.</strong> Supervised Fine-Tuning</a></li><li class="chapter-item expanded "><a href="llms/fine_tuning/rlhf.html" target="_parent"><strong aria-hidden="true">1.3.2.</strong> RLHF</a></li><li class="chapter-item expanded "><a href="llms/fine_tuning/dpo.html" target="_parent"><strong aria-hidden="true">1.3.3.</strong> DPO</a></li><li class="chapter-item expanded "><a href="llms/fine_tuning/grpo.html" target="_parent"><strong aria-hidden="true">1.3.4.</strong> GRPO</a></li><li class="chapter-item expanded "><a href="llms/fine_tuning/peft.html" target="_parent"><strong aria-hidden="true">1.3.5.</strong> PEFT</a></li><li class="chapter-item expanded "><a href="llms/fine_tuning/lora.html" target="_parent"><strong aria-hidden="true">1.3.6.</strong> LoRA</a></li><li class="chapter-item expanded "><a href="llms/fine_tuning/qlora.html" target="_parent"><strong aria-hidden="true">1.3.7.</strong> QLoRA</a></li><li class="chapter-item expanded "><a href="llms/fine_tuning/dora.html" target="_parent"><strong aria-hidden="true">1.3.8.</strong> DoRA</a></li></ol></li><li class="chapter-item expanded "><a href="llms/agents/index.html" target="_parent"><strong aria-hidden="true">1.4.</strong> Agents</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="llms/agents/tool_use.html" target="_parent"><strong aria-hidden="true">1.4.1.</strong> Tool Use</a></li><li class="chapter-item expanded "><a href="llms/agents/reflection.html" target="_parent"><strong aria-hidden="true">1.4.2.</strong> Reflection</a></li><li class="chapter-item expanded "><a href="llms/agents/multi_agents.html" target="_parent"><strong aria-hidden="true">1.4.3.</strong> Multi Agent</a></li><li class="chapter-item expanded "><a href="llms/agents/planning.html" target="_parent"><strong aria-hidden="true">1.4.4.</strong> Planning</a></li></ol></li><li class="chapter-item expanded "><a href="llms/rag/index.html" target="_parent"><strong aria-hidden="true">1.5.</strong> RAG</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="llms/rag/chunks.html" target="_parent"><strong aria-hidden="true">1.5.1.</strong> Chunks</a></li><li class="chapter-item expanded "><a href="llms/rag/sliding_window.html" target="_parent"><strong aria-hidden="true">1.5.2.</strong> Sliding Window</a></li><li class="chapter-item expanded "><a href="llms/rag/graph.html" target="_parent"><strong aria-hidden="true">1.5.3.</strong> Graph RAG</a></li></ol></li><li class="chapter-item expanded "><a href="llms/compression/index.html" target="_parent"><strong aria-hidden="true">1.6.</strong> Model Compression</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="llms/compression/distillation.html" target="_parent"><strong aria-hidden="true">1.6.1.</strong> Distillation</a></li><li class="chapter-item expanded "><a href="llms/compression/quantization.html" target="_parent"><strong aria-hidden="true">1.6.2.</strong> Quantization</a></li></ol></li><li class="chapter-item expanded "><a href="llms/efficient_inference/index.html" target="_parent"><strong aria-hidden="true">1.7.</strong> Efficient Inference</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="llms/efficient_inference/fast_attention.html" target="_parent"><strong aria-hidden="true">1.7.1.</strong> Fast Attention</a></li><li class="chapter-item expanded "><a href="llms/efficient_inference/distillation.html" target="_parent"><strong aria-hidden="true">1.7.2.</strong> Distillation</a></li><li class="chapter-item expanded "><a href="llms/efficient_inference/quantization.html" target="_parent"><strong aria-hidden="true">1.7.3.</strong> Quantization</a></li></ol></li><li class="chapter-item expanded "><a href="llms/decoding/index.html" target="_parent"><strong aria-hidden="true">1.8.</strong> Decoding</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="llms/decoding/multi_token_prediction.html" target="_parent"><strong aria-hidden="true">1.8.1.</strong> Multi-Token Prediction</a></li><li class="chapter-item expanded "><a href="llms/decoding/top_k.html" target="_parent"><strong aria-hidden="true">1.8.2.</strong> Top-k</a></li><li class="chapter-item expanded "><a href="llms/decoding/greedy.html" target="_parent"><strong aria-hidden="true">1.8.3.</strong> Greedy</a></li><li class="chapter-item expanded "><a href="llms/decoding/speculative.html" target="_parent"><strong aria-hidden="true">1.8.4.</strong> Speculative</a></li></ol></li><li class="chapter-item expanded "><a href="llms/misc/index.html" target="_parent"><strong aria-hidden="true">1.9.</strong> Miscellaneous</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="llms/misc/rejection_sampling.html" target="_parent"><strong aria-hidden="true">1.9.1.</strong> Rejection Sampling</a></li><li class="chapter-item expanded "><a href="llms/misc/emergent.html" target="_parent"><strong aria-hidden="true">1.9.2.</strong> Emergent</a></li><li class="chapter-item expanded "><a href="llms/misc/llm_as_judge.html" target="_parent"><strong aria-hidden="true">1.9.3.</strong> LLM As Judge</a></li></ol></li></ol></li><li class="chapter-item expanded "><a href="models/index.html" target="_parent"><strong aria-hidden="true">2.</strong> Notable Models</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="models/bert.html" target="_parent"><strong aria-hidden="true">2.1.</strong> BERT</a></li><li class="chapter-item expanded "><a href="models/llama_3.html" target="_parent"><strong aria-hidden="true">2.2.</strong> Llama-3</a></li><li class="chapter-item expanded "><a href="models/deepseek_r1.html" target="_parent"><strong aria-hidden="true">2.3.</strong> DeepSeek-R1</a></li><li class="chapter-item expanded "><a href="models/deepseek_v3.html" target="_parent"><strong aria-hidden="true">2.4.</strong> DeepSeek-v3</a></li></ol></li><li class="chapter-item expanded "><li class="part-title">Evaluation</li><li class="chapter-item expanded "><a href="evaluation/index.html" target="_parent"><strong aria-hidden="true">3.</strong> Metrics</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="evaluation/rouge.html" target="_parent"><strong aria-hidden="true">3.1.</strong> Rouge</a></li><li class="chapter-item expanded "><a href="evaluation/bleu.html" target="_parent"><strong aria-hidden="true">3.2.</strong> Bleu</a></li><li class="chapter-item expanded "><a href="evaluation/pass_k.html" target="_parent"><strong aria-hidden="true">3.3.</strong> pass@k</a></li></ol></li></ol>
    </body>
</html>
