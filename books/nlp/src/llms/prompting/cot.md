# Chain of Thought

<!-- Header -->

{{ #aipr_header }}

<!-- Main Body -->

The Chain of Thought (CoT) prompting technique, introduced by Wei, Jason et al (2022),
encourages an LLM to articulate its reasoning steps before arriving at a final
answer to a given task.

Before its introduction, scaling LLMs had demonstrated the ability to generate coherent
text and solve various tasks. However, these LLMs still underperformed on
complex reasoning tasks like arithmetic and symbolic reasoning. While some prompting
techniques and [in-context learning](./icl.md) had been discovered, none had successfully
enabled LLMs to handle complex reasoning tasks.

## Performance

## Modern Usage

## CoT and Reasoning LLMs

## Limitations

#### References & Useful Links <!-- markdownlint-disable-line MD001 -->

1. [_Wei, Jason, et al. "Chain-of-thought prompting elicits reasoning in large
   language models." Advances in neural information processing systems 35 (2022):
   24824-24837._](https://arxiv.org/pdf/2106.09685)

<!-- Contributions -->

{{ #author nerdai }}
